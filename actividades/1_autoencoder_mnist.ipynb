{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset y Dataloaders\n",
    "\n",
    "Usaremos la base de datos MNIST de dígitos manuscritos\n",
    "\n",
    "Corresponden a imágenes de 28x28 píxeles en blanco y negro\n",
    "\n",
    "Esta base de datos viene incluida en el [módulo datasets de la librería torchvision](https://pytorch.org/docs/stable/torchvision/datasets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_train_data = datasets.MNIST(root='~/datasets/',\n",
    "                                  train=True, download=True,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "mnist_test_data = datasets.MNIST(root='~/datasets/',\n",
    "                                 train=False, download=True, \n",
    "                                 transform=transforms.ToTensor())\n",
    "\n",
    "image, label = mnist_train_data[0]\n",
    "display(len(mnist_train_data), type(image), image.dtype, type(label))\n",
    "fig, ax = plt.subplots(1, 10, figsize=(8, 1.5), tight_layout=True)\n",
    "idx = np.random.permutation(len(mnist_train_data))[:10]\n",
    "for k in range(10):\n",
    "    image, label = mnist_train_data[idx[k]]\n",
    "    ax[k].matshow(image[0, :, :].numpy(), cmap=plt.cm.Greys_r)\n",
    "    ax[k].axis('off');\n",
    "    ax[k].set_title(label)\n",
    "    \n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import sklearn.model_selection\n",
    "\n",
    "# Set de entrenamiento y validación estratíficados\n",
    "sss = sklearn.model_selection.StratifiedShuffleSplit(train_size=0.75).split(mnist_train_data.data, \n",
    "                                                                            mnist_train_data.targets)\n",
    "train_idx, valid_idx = next(sss)\n",
    "\n",
    "# Data loader de entrenamiento\n",
    "train_dataset = Subset(mnist_train_data, train_idx)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "# Data loader de validación\n",
    "valid_dataset = Subset(mnist_train_data, valid_idx)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder \n",
    "\n",
    "- [Revisar material teórico entre las láminas 96 y 102](https://docs.google.com/presentation/d/1IJ2n8X4w8pvzNLmpJB-ms6-GDHWthfsJTFuyUqHfXg8/present#slide=id.g3d5022dff0_1_100)\n",
    "- [Revisar tutorial de Pytorch](https://github.com/phuijse/INFO257/blob/master/notebooks/clases/1_pytorch_tutorial.ipynb) y [clase redes convolucionales](https://github.com/phuijse/INFO257/blob/master/notebooks/clases/4_red_convolucional.ipynb)\n",
    "\n",
    "\n",
    "Completemos el modelo de autoencoder que se propone a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, ...):\n",
    "        super(type(self), self).__init__()\n",
    "        \n",
    "        # Completar\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # Completar\n",
    "        return x\n",
    "        \n",
    "    def decode(self, z):\n",
    "        # Completar\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z)\n",
    "    \n",
    "model = Autoencoder()\n",
    "display(model)\n",
    "\n",
    "x = mnist_train_data[0][0]\n",
    "xhat = model.forward(x.view(1, 28*28)).view(1, 28, 28).detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 2), tight_layout=True)\n",
    "ax[0].matshow(x[0], cmap=plt.cm.Greys_r)\n",
    "ax[0].set_title('Original'); ax[0].axis('off')\n",
    "ax[1].matshow(xhat[0], cmap=plt.cm.Greys_r)\n",
    "ax[1].set_title('Reconstruida'); ax[1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento\n",
    "\n",
    "- Para actualizar los parámetros usaremos el optimizar Adam\n",
    "- Transformamos las imágenes de MNIST al rango [0, 1] y usamos la entropía cruzada binaria como función de costo. Interpretamos la salida como logaritmos de probabilidades (logits)\n",
    "- Utilizaremos la librería de alto nivel [`ignite`](https://pytorch.org/ignite/) para entrenar y el dashboard `tensorboard` para visualizar los entrenamientos\n",
    "\n",
    "No olvides lanzar el dashboard\n",
    "\n",
    "    tensorboard --logdit /tmp/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234) # Por reproducibilidad\n",
    "max_epochs = 100  \n",
    "model = Autoencoder()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda:0')\n",
    "\n",
    "def train_one_step(engine, batch): \n",
    "    model.train()\n",
    "    x, y = batch # Desenpaquetamos el minibatch\n",
    "    x, y = x.to(device), y.to(device) # Enviamos los datos a GPU\n",
    "    x = x.view(-1, 28*28) # Aplanar las imágenes\n",
    "    optimizer.zero_grad() # Reseteamos los gradientes\n",
    "    xhat = model.forward(x) # Reproducimos la entrada\n",
    "    loss = criterion(xhat, x) # Medimos el error entre la entrada y la reconstrucción\n",
    "    loss.backward() # Calculamos los gradientes\n",
    "    optimizer.step() # Actualizamos los parámetros\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_one_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.view(-1, 28*28) # Aplanar las imágenes\n",
    "        xhat = model.forward(x)\n",
    "        loss = criterion(xhat, x)\n",
    "        return xhat, x\n",
    "    \n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Loss, Accuracy\n",
    "\n",
    "metrics = {'Loss': Loss(criterion)}\n",
    "trainer = Engine(train_one_step)\n",
    "evaluator = Engine(evaluate_one_step)\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(evaluator, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "\n",
    "# Contexto de escritura de datos para tensorboard\n",
    "with SummaryWriter(log_dir=f'/tmp/tensorboard/run{time.time_ns()}') as writer:\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED(every=1)) # Cada 1 epocas\n",
    "    def log_results(engine):\n",
    "        evaluator.run(train_loader) # Evaluo el conjunto de entrenamiento\n",
    "        writer.add_scalar(\"train/loss\", evaluator.state.metrics['Loss'], engine.state.epoch)\n",
    "        \n",
    "        evaluator.run(valid_loader) # Evaluo el conjunto de validación\n",
    "        writer.add_scalar(\"valid/loss\", evaluator.state.metrics['Loss'], engine.state.epoch)\n",
    "        \n",
    "        print(f\"Epoca: {engine.state.epoch} Valid loss: {evaluator.state.metrics['Loss']:.4f}\")\n",
    "\n",
    "    best_model_handler = ModelCheckpoint(dirname='.', require_empty=False, filename_prefix=\"best\", n_saved=1,\n",
    "                                         score_function=lambda engine: -engine.state.metrics['Loss'],\n",
    "                                         score_name=\"val_loss\")\n",
    "\n",
    "    # Lo siguiente se ejecuta cada ves que termine el loop de validación\n",
    "    evaluator.add_event_handler(Events.COMPLETED, \n",
    "                                best_model_handler, {'ae': model})\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspección de resultados\n",
    "\n",
    "Primero recuperamos el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "model.load_state_dict(torch.load('best_ae_val_loss=-0.1856.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de las reconstrucciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 10, figsize=(8, 3))\n",
    "P = np.random.permutation(10000)\n",
    "\n",
    "for i in range(10):\n",
    "    image, label = mnist_test_data[P[i]]\n",
    "    hat_image = nn.Sigmoid()(model.forward(image.view(1, 28*28))).view(1, 28, 28)\n",
    "    axs[0, i].matshow(image.numpy()[0], cmap=plt.cm.Greys_r)\n",
    "    axs[0, i].axis('off');\n",
    "    axs[0, i].set_title(label)\n",
    "    axs[1, i].matshow(hat_image.detach().numpy()[0], cmap=plt.cm.Greys_r)\n",
    "    axs[1, i].axis('off');\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización del espacio latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4), dpi=80)\n",
    "ax_main = plt.subplot2grid((2, 3), (0, 0), colspan=2, rowspan=2)\n",
    "ax_ori = plt.subplot2grid((2, 3), (0, 2))\n",
    "ax_rec = plt.subplot2grid((2, 3), (1, 2))\n",
    "ax_ori.axis('off'); ax_rec.axis('off');\n",
    "\n",
    "N = test_loader.dataset.__len__()\n",
    "test_targets = mnist_test_data.targets.numpy()\n",
    "code_targets = []\n",
    "for x, y in test_loader:\n",
    "    z = model.encode(x.view(-1, 28*28))\n",
    "    code_targets.append(z)\n",
    "code_targets = torch.cat(code_targets).detach().numpy()\n",
    "\n",
    "for digit in range(10):\n",
    "    ax_main.scatter(code_targets[test_targets == digit, 0], \n",
    "                    code_targets[test_targets == digit, 1], \n",
    "                    s=5, alpha=0.5, label=str(digit))\n",
    "ax_main.legend();\n",
    "\n",
    "def onclick(event):\n",
    "    code_closest = [event.xdata, event.ydata]\n",
    "    idx = np.argmin(np.sum((code_targets - code_closest)**2, axis=1))\n",
    "    image, label = mnist_test_data[idx]\n",
    "    hat_image = nn.Sigmoid()(model.forward(image.view(1, 28*28))).view(1, 28, 28)\n",
    "    ax_ori.matshow(mnist_test_data[idx][0].numpy()[0], cmap=plt.cm.Greys_r)\n",
    "    ax_rec.matshow(hat_image.detach().numpy()[0], cmap=plt.cm.Greys_r)\n",
    "    \n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
